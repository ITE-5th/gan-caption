`{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4G0w52jm818m"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I13lfyu38m5Z"
   },
   "source": [
    "## Install cuda, cudnn, pytorch...\n",
    "1.   Download & Install CUDA\n",
    "2.   Download & Install Pytorch\n",
    "3.   Download & Install CV2\n",
    "4.   Download & Install Deeplearning Toolkit for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zUFxs3Kd8qst"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-05-13 22:30:32--  https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb\n",
      "Resolving developer.nvidia.com (developer.nvidia.com)... 79.143.180.106\n",
      "Connecting to developer.nvidia.com (developer.nvidia.com)|79.143.180.106|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: http://developer.download.nvidia.com/compute/cuda/8.0/secure/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64.deb?VZzg2Ka7aW9of6Uum6hStCVqCnoMssT4YYOGjiuJBKRLFYhVsdyWj4XQfflUqS3W3qNsTII3GNmSOljppeWYCV3eDV0Oja_plWGQkm4IFUQi4y6PlokEB1j3JgbFFTGRuRPrWicHsnLA0uhLHaA0TW_z4RCL4wi54MRJWdFx_qAmfias8Uv7fNqGTp8mJXTg4lVeeMddvQB6P1FOC2so3vsR4g [following]\n",
      "--2018-05-13 22:30:34--  http://developer.download.nvidia.com/compute/cuda/8.0/secure/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64.deb?VZzg2Ka7aW9of6Uum6hStCVqCnoMssT4YYOGjiuJBKRLFYhVsdyWj4XQfflUqS3W3qNsTII3GNmSOljppeWYCV3eDV0Oja_plWGQkm4IFUQi4y6PlokEB1j3JgbFFTGRuRPrWicHsnLA0uhLHaA0TW_z4RCL4wi54MRJWdFx_qAmfias8Uv7fNqGTp8mJXTg4lVeeMddvQB6P1FOC2so3vsR4g\n",
      "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 79.143.180.106\n",
      "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|79.143.180.106|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1913589814 (1.8G) [application/x-deb]\n",
      "Saving to: ‘cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb’\n",
      "\n",
      "buntu1604-8-0-local   0%[                    ] 671.84K  70.9KB/s    eta 6h 29m "
     ]
    }
   ],
   "source": [
    "!wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb\n",
    "!dpkg -i ./cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb\n",
    "!apt-key add /var/cuda-repo-8-0-local-ga2/7fa2af80.pub\n",
    "!apt update\n",
    "!apt install cuda-8-0 -y\n",
    "import os\n",
    "os.environ['PATH'] += ':/usr/local/cuda/bin'\n",
    "\n",
    "# http://pytorch.org/\n",
    "from os import path\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "\n",
    "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "\n",
    "!pip install torch torchvision\n",
    "# !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
    "import torch\n",
    "\n",
    "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n",
    "import cv2\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "A6OZW2av8dLU"
   },
   "outputs": [],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once per notebook.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Download a file based on its file ID.\n",
    "#\n",
    "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
    "file_id = '1qR_h9jNPGaufbhW1PZoxyZXLN7ZReK-V'\n",
    "downloaded = drive.CreateFile({'id': file_id})\n",
    "downloaded.FetchContent()\n",
    "with open(\"./cudnn.tar.gz\" , \"wb\") as f:\n",
    "  f.write(downloaded.content.read())\n",
    "  f.close()\n",
    "  \n",
    "!tar -xzvf cudnn.tar.gz\n",
    "!cp cuda/include/cudnn.h /usr/local/cuda/include\n",
    "!cp cuda/lib64/libcudnn* /usr/local/cuda/lib64\n",
    "!chmod a+r /usr/local/cuda/include/cudnn.h\n",
    "\n",
    "!cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2\n",
    "!cat /usr/include/cudnn.h | grep CUDNN_MAJOR -A 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GxfIS_Op6Ib1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH'] += ':/usr/local/cuda/bin'\n",
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xoYhR0Y18TZE"
   },
   "outputs": [],
   "source": [
    "!kill -9 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "exyzLS17Qeza"
   },
   "outputs": [],
   "source": [
    "!apt install --reinstall cuda-8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9kgLS4IgieSm"
   },
   "outputs": [],
   "source": [
    "# !pip install --no-cache-dir -I pillow\n",
    "!pip install Cython\n",
    "!cd ~; git clone https://github.com/cocodataset/cocoapi.git; cd ~/cocoapi/PythonAPI; make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cz5I_CjQx7ZW"
   },
   "outputs": [],
   "source": [
    "%cd ~/cocoapi/PythonAPI\n",
    "!python setup.py build_ext install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jeQ-vz_Rr0wW"
   },
   "outputs": [],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mMBbTWWLMHfu"
   },
   "outputs": [],
   "source": [
    "!apt --fix-broken install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XTE62FCnKqqy"
   },
   "outputs": [],
   "source": [
    "!pip uninstall pillow -y\n",
    "!CC=\"cc -mavx2\" pip install -U --force-reinstall pillow-simd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "92qHH0sFiMUI"
   },
   "source": [
    "## Clone The Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SVghZVUuiMqJ"
   },
   "outputs": [],
   "source": [
    "%cd ~\n",
    "%rm -r gan-caption\n",
    "!git clone https://github.com/ITE-5th/gan-caption.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "o8R56oLJOfHN"
   },
   "outputs": [],
   "source": [
    "!cd ~/gan-caption/; git pull origin master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "83FPCo8TO9xN"
   },
   "source": [
    "# Download COCO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EzThi65s47DE"
   },
   "outputs": [],
   "source": [
    "%cd ~/gan-caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yh14k7wZPAaO"
   },
   "outputs": [],
   "source": [
    "# download coco 2017\n",
    "!wget --directory-prefix=./data \"http://images.cocodataset.org/zips/train2017.zip\"\n",
    "!unzip ./data/train2017.zip -d ./data/\n",
    "!mv ./data/train2017 ./data/train\n",
    "!rm ./data/train2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wX1Y_BbHGNPY"
   },
   "outputs": [],
   "source": [
    "!cd data/train/; ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zM-jnvNlBpRc"
   },
   "outputs": [],
   "source": [
    "# Validation Dataset\n",
    "!wget --directory-prefix=./data \"http://images.cocodataset.org/zips/val2017.zip\"\n",
    "!unzip ./data/val2017.zip -d ./data/\n",
    "!mv ./data/val2017 ./data/val\n",
    "!rm ./data/val2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5aiZg8hONwy7"
   },
   "outputs": [],
   "source": [
    "# download coco annotation\n",
    "!wget --directory-prefix=./data \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "!unzip ./data/annotations_trainval2017.zip -d ./data/\n",
    "# !mv ./data/annotations_trainval2017 ./data/annotations\n",
    "!rm ./data/annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8GxBcjJJEhi2"
   },
   "outputs": [],
   "source": [
    "!cd ./data/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JBn-vR5C2J-U"
   },
   "outputs": [],
   "source": [
    "!pip uninstall pretrainedmodels -y\n",
    "!pip install pretrainedmodels --no-cache\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "x8PXaWg2rZJg"
   },
   "outputs": [],
   "source": [
    "import pretrainedmodels\n",
    "vgg = pretrainedmodels.vgg16()\n",
    "vgg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Q_QX2ILmbj_0"
   },
   "outputs": [],
   "source": [
    "vgg.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xUHATK9BbWQv"
   },
   "source": [
    "# Save to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tpKF2uPQbgtW"
   },
   "outputs": [],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once per notebook.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "drive_service = build('drive', 'v3')\n",
    "\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "def upload_file(file_name): \n",
    "    %cd ~/gan-caption/models\n",
    "    file_metadata = {\n",
    "      'name': file_name,\n",
    "    }\n",
    "    media = MediaFileUpload(file_name, \n",
    "                            resumable=True)\n",
    "    created = drive_service.files().create(body=file_metadata,\n",
    "                                           media_body=media,\n",
    "                                           fields='id').execute()\n",
    "    print('File ID: {}'.format(created.get('id')))\n",
    "    %cd ~/gan-caption/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3LComAKJeq_Z"
   },
   "outputs": [],
   "source": [
    "file_name = \"generator-e20.pth\"\n",
    "torch.save({\"state_dict\": generator.state_dict()},\n",
    "               FilePathManager.resolve(f\"models/{file_name}\"))\n",
    "upload_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4XlTXNgaQSi8"
   },
   "outputs": [],
   "source": [
    "file_name = f\"generator-c{epoch}.pth\"\n",
    "torch.save({\"state_dict\": generator.state_dict(), 'optimizer': optimizer.state_dict()},\n",
    "           FilePathManager.resolve(f\"models/{file_name}\"))\n",
    "upload_file(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1kY5CwUGoeJU"
   },
   "source": [
    "# Pretrained from Google Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YwFECo4z6xXn"
   },
   "outputs": [],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once per notebook.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# List .txt files in the root.\n",
    "#\n",
    "# Search query reference:\n",
    "# https://developers.google.com/drive/v2/web/search-parameters\n",
    "listed = drive.ListFile({'q': \"title contains '.pth' and 'root' in parents\"}).GetList()\n",
    "for file in listed:\n",
    "  print('title {}, id {}'.format(file['title'], file['id']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Yoa5z2MA65H2"
   },
   "outputs": [],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Download a file based on its file ID.\n",
    "#\n",
    "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
    "file_id = '13RLysDRZnPAiV0LOrjJCBP6KSFwIylcj'\n",
    "# file_id = '1qyYwku2lN9Fy-A3dLK_eLzlxPwIAjyrt'\n",
    "downloaded = drive.CreateFile({'id': file_id})\n",
    "downloaded.FetchContent()\n",
    "with open(\"./models/generator.pth\" , \"wb\") as f:\n",
    "  f.write(downloaded.content.read())\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ioyXtcu_5F7K"
   },
   "outputs": [],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Download a file based on its file ID.\n",
    "#\n",
    "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
    "file_id = '1-XjpekBaARtdGOa2luBP3FVeB0IfCqLG'\n",
    "# file_id = '1ECdrFSSR3x9-W339PaF6Ed9qylNMrq0C'\n",
    "downloaded = drive.CreateFile({'id': file_id})\n",
    "downloaded.FetchContent()\n",
    "with open(\"./models/evaluator.pth\" , \"wb\") as f:\n",
    "  f.write(downloaded.content.read())\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q1EY8dAc2tou"
   },
   "source": [
    "# Generator & Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0GZUX113oreS"
   },
   "outputs": [],
   "source": [
    "%cd ~/gan-caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pfx8LeqpR6mu"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "class Captions:\n",
    "    def __init__(self, dataset, corpus, captions_per_image):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.corpus = corpus\n",
    "        self.captions_per_image = captions_per_image\n",
    "\n",
    "    def get_gt(self, indices):\n",
    "        result = []\n",
    "        ids = np.asarray(self.dataset.captions.ids)\n",
    "        for i in range(indices.shape[0]):\n",
    "            anns = self.dataset.captions.coco.loadAnns(self.dataset.captions.coco.getAnnIds(imgIds=ids[indices[i]]))\n",
    "            target = np.asarray([ann['caption'] for ann in anns])\n",
    "\n",
    "            gt = torch.stack([self.corpus.embed_sentence(target[i], one_hot=False) for i in range(self.captions_per_image)])\n",
    "            result.append(gt)\n",
    "\n",
    "        return torch.stack(result)\n",
    "\n",
    "    def get_caption(self, index, caption_index):\n",
    "        img_id = self.dataset.captions.ids[index]\n",
    "        ann_ids = self.dataset.captions.coco.getAnnIds(imgIds=img_id)\n",
    "        anns = self.dataset.captions.coco.loadAnns(ann_ids)\n",
    "        return anns[caption_index]['caption']\n",
    "\n",
    "    def get_others(self, indices):\n",
    "        others = []\n",
    "        for i in range(len(indices)):\n",
    "            s = set(np.arange(self.dataset.length))\n",
    "            s.remove(indices[i])\n",
    "            s = list(s)\n",
    "            for _ in range(self.captions_per_image):\n",
    "                index = random.choice(s)\n",
    "                caption_index = random.choice(range(self.captions_per_image))\n",
    "                caption = self.get_caption(index, caption_index)\n",
    "                others.append(self.corpus.embed_sentence(caption, one_hot=False))\n",
    "\n",
    "        return torch.stack(others)\n",
    "\n",
    "    def get_captions(self, indices):\n",
    "        indices = indices.cpu().numpy()\n",
    "        gt = self.get_gt(indices)\n",
    "        others = self.get_others(indices)\n",
    "        return gt.view(-1, gt.shape[-2], gt.shape[-1]), others\n",
    "    \n",
    "    def get_only_gt(self, indices):\n",
    "        indices = indices.cpu().numpy()\n",
    "        gt = self.get_gt(indices)\n",
    "        return gt.view(-1, gt.shape[-2], gt.shape[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hocPN2QvSCRm"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from corpus import Corpus\n",
    "from file_path_manager import FilePathManager\n",
    "\n",
    "\n",
    "class CocoDataset(Dataset):\n",
    "\n",
    "    def __init__(self, tranform=None, length=None):\n",
    "        self.captions = dset.CocoCaptions(root=FilePathManager.resolve(f'data/train'),\n",
    "                                          annFile=FilePathManager.resolve(\n",
    "                                              f\"data/annotations/captions_train2017.json\"),\n",
    "                                          transform=tranform)\n",
    "\n",
    "        self.captions_per_image = captions_per_image\n",
    "        \n",
    "        self.length = length\n",
    "        if length is None:\n",
    "          self.length = len(self.captions)\n",
    "        self.s = set(range(self.length))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.captions[index][0], index\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "N15ujh3--I2Q"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from corpus import Corpus\n",
    "from file_path_manager import FilePathManager\n",
    "\n",
    "\n",
    "class ECocoDataset(Dataset):\n",
    "\n",
    "    def __init__(self, corpus: Corpus, evaluator: bool = True, tranform=None):\n",
    "        self.corpus = corpus\n",
    "        self.evaluator = evaluator\n",
    "        self.captions = dset.CocoCaptions(root=FilePathManager.resolve(f'data/train'),\n",
    "                                          annFile=FilePathManager.resolve(\n",
    "                                              f\"data/annotations/captions_train2017.json\"),\n",
    "                                          transform=tranform)\n",
    "\n",
    "        self.length = len(self.captions)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, caption = self.captions[index]\n",
    "        captions = torch.stack([self.corpus.embed_sentence(caption[i], one_hot=False) for i in range(5)])\n",
    "        others = []\n",
    "\n",
    "        s = set(range(self.length))\n",
    "        s.remove(index)\n",
    "        s = list(s)\n",
    "        for i in range(5):\n",
    "            other_index = random.choice(s)\n",
    "            other_caption = self.get_captions(other_index)\n",
    "            other_index = random.choice(range(5))\n",
    "            other_caption = other_caption[other_index]\n",
    "            other_caption = self.corpus.embed_sentence(other_caption, one_hot=False)\n",
    "            others.append(other_caption)\n",
    "\n",
    "        others = torch.stack(others)\n",
    "        return image, captions, others\n",
    "\n",
    "    def get_captions(self, index):\n",
    "        coco = self.captions.coco\n",
    "        img_id = self.captions.ids[index]\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "        target = [ann['caption'] for ann in anns]\n",
    "\n",
    "        return target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "STNtiHio-JyS"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "from joblib import cpu_count\n",
    "from pretrainedmodels import utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from corpus import Corpus\n",
    "from file_path_manager import FilePathManager\n",
    "\n",
    "\n",
    "class GCocoDataset(Dataset):\n",
    "\n",
    "    def __init__(self, corpus: Corpus, transform=None, captions_per_image=2):\n",
    "        self.corpus = corpus\n",
    "        self.captions = dset.CocoCaptions(root=FilePathManager.resolve(f'data/train'),\n",
    "                                          annFile=FilePathManager.resolve(\n",
    "                                              f\"data/annotations/captions_train2017.json\"),\n",
    "                                          transform=transform)\n",
    "        self.captions_per_image = captions_per_image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         print(index)\n",
    "        image, caption = self.captions[index]\n",
    "        inputs = torch.stack(\n",
    "            [self.corpus.embed_sentence(caption[i], one_hot=False) for i in range(self.captions_per_image)])\n",
    "        targets = torch.stack([self.corpus.sentence_indices(caption[i]) for i in range(self.captions_per_image)])\n",
    "        return image, inputs, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.captions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aMviChfi3_fa"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Xhxi_ZXNzLOk"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import cpu_count\n",
    "import copy\n",
    "import torch\n",
    "from pretrainedmodels import utils\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from conditional_generator import ConditionalGenerator\n",
    "from corpus import Corpus\n",
    "from evaluator import Evaluator\n",
    "from evaluator_loss import EvaluatorLoss\n",
    "from file_path_manager import FilePathManager\n",
    "from vgg16_extractor import Vgg16Extractor\n",
    "from rl_loss import RLLoss\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(2016)\n",
    "np.random.seed(2016)\n",
    "\n",
    "lr1 = 4e-4\n",
    "lr2 = 4e-4\n",
    "alpha = 1\n",
    "beta = 1\n",
    "captions_per_image = 5\n",
    "max_length = 17\n",
    "\n",
    "\n",
    "extractor = Vgg16Extractor(transform=False)\n",
    "\n",
    "corpus = Corpus.load(FilePathManager.resolve(\"data/corpus-old.pkl\"), max_length)\n",
    "evaluator = Evaluator.load(corpus).cuda()\n",
    "generator = ConditionalGenerator.load(corpus).cuda()\n",
    "\n",
    "# g_dataset = GCocoDataset(corpus, tranform=utils.TransformImage(extractor.cnn), captions_per_image=captions_per_image)\n",
    "e_dataset = ECocoDataset(corpus, tranform=utils.TransformImage(extractor.cnn))\n",
    "dataset = CocoDataset(tranform=utils.TransformImage(extractor.cnn))\n",
    "captions_loader = Captions(dataset, corpus, captions_per_image)\n",
    "\n",
    "\n",
    "evaluator_criterion = EvaluatorLoss(alpha, beta).cuda()\n",
    "generator_criterion = RLLoss().cuda()\n",
    "generator.unfreeze()\n",
    "evaluator.unfreeze()\n",
    "\n",
    "evaluator_optimizer = optim.Adam(evaluator.parameters(), lr=lr1, weight_decay=1e-5)\n",
    "generator_optimizer = optim.Adam(generator.parameters(), lr=lr2, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yg1xXeez53_0"
   },
   "outputs": [],
   "source": [
    "#g_dataloader = DataLoader(g_dataset, batch_size=36, shuffle=True, num_workers=1)\n",
    "e_dataloader = DataLoader(e_dataset, batch_size=24, shuffle=True, num_workers=1)\n",
    "dataloader = DataLoader(dataset, batch_size=36, shuffle=True, num_workers=1)\n",
    "epochs = 1\n",
    "monte_carlo_count = 16\n",
    "print(f\"number of batches = {len(dataset) // 36}\")\n",
    "print(f\"number of batches = {len(e_dataset) // 24}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "G_sCAhlA6HnO"
   },
   "outputs": [],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TTdMrfZUYQhY"
   },
   "outputs": [],
   "source": [
    "#4549 => 26, 7sec\n",
    "#3942 => 30, 8.8sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "raHRrml95PKk"
   },
   "source": [
    "## load pretrained Generator + Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "D8O_DFiX5Sga"
   },
   "outputs": [],
   "source": [
    "generator = ConditionalGenerator(corpus).cuda()\n",
    "state_dict = torch.load('./models/generator.pth')\n",
    "generator.load_state_dict(state_dict['state_dict'])\n",
    "generator.eval()\n",
    "generator.train(True)\n",
    "lll = state_dict\n",
    "\n",
    "state_dict = torch.load('./models/evaluator.pth')\n",
    "evaluator.load_state_dict(state_dict['state_dict'])\n",
    "evaluator.eval()\n",
    "evaluator.train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "n9LnqgABTsFE"
   },
   "outputs": [],
   "source": [
    "generator.unfreeze()\n",
    "evaluator.unfreeze()\n",
    "evaluator_optimizer = optim.Adam(evaluator.parameters(), lr=lr1, weight_decay=1e-5)\n",
    "generator_optimizer = optim.Adam(generator.parameters(), lr=lr2,betas=(0.8, 0.999), weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qyJsbiQI2LGU"
   },
   "outputs": [],
   "source": [
    "all_losses = []\n",
    "g_losses = []\n",
    "e_losses = []\n",
    "max_length = 17\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wNqHHf2t-3uk"
   },
   "source": [
    "## New Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MboE5T5K_L6m"
   },
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "torch.manual_seed(2016)\n",
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "\n",
    "print(\"Begin Training\")\n",
    "epoch_loss = 0\n",
    "start = time.time()\n",
    "epoch_loss = 0\n",
    "batch_loss = 0\n",
    "generator.freeze()\n",
    "\n",
    "for i, (images, captions, other_captions) in enumerate(e_dataloader):\n",
    "\n",
    "    print(f\"Batch = {i}, Time: {time.time() - start}, Batch Loss: {batch_loss}, Loss: {epoch_loss}\")\n",
    "\n",
    "    images, captions, other_captions = images.cuda(), captions.cuda(), other_captions.cuda()\n",
    "    images = extractor.forward(Variable(images))\n",
    "    captions = captions.view(-1, max_length, captions.shape[-1])\n",
    "    other_captions = other_captions.view(-1, max_length, other_captions.shape[-1])\n",
    "\n",
    "    k = images.shape[0] \n",
    "    images = torch.stack([images] * 5).permute(1,0, 2).contiguous().view(-1, images.shape[-1])    \n",
    "\n",
    "    captions = pack_padded_sequence(captions, [max_length] * k * 5, True)\n",
    "    other_captions = pack_padded_sequence(other_captions, [max_length] * k * 5, True)\n",
    "    evaluator_optimizer.zero_grad()\n",
    "\n",
    "    generator_outputs = generator.sample_with_embedding(images)\n",
    "\n",
    "    evaluator_outputs = evaluator(images, captions)\n",
    "    generator_outputs = evaluator(images, generator_outputs)\n",
    "    other_outputs = evaluator(images, other_captions)\n",
    "\n",
    "    loss = evaluator_criterion(evaluator_outputs, generator_outputs, other_outputs)\n",
    "\n",
    "    batch_loss = loss.item()\n",
    "    epoch_loss += batch_loss\n",
    "\n",
    "    loss.backward()\n",
    "    evaluator_optimizer.step()\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "losses.append(epoch_loss)\n",
    "print(f\"Epoch: {epoch}, Time: {end - start}, Loss: {epoch_loss}\")\n",
    "start = end\n",
    "# file_name = f\"evaluator-{epoch}.pth\"\n",
    "# torch.save({\"state_dict\": evaluator.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': losses, 'alpha': alpha, 'beta':beta,'lr':lr, 'epoch': epoch},\n",
    "#            FilePathManager.resolve(f\"models/{file_name}\"))\n",
    "# upload_file(file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BA0f5EGZcS4m"
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Uj5z3jQNqw4g"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(2016)\n",
    "np.random.seed(2016)\n",
    "\n",
    "generator.unfreeze()\n",
    "evaluator.freeze()\n",
    "print(\"Begin Training Generator\")\n",
    "\n",
    "start = time.time()\n",
    "generator_loss = 0\n",
    "batch_time = time.time()\n",
    "batch_loss = 0\n",
    "for i, (images, indices) in enumerate(dataloader):\n",
    "    images = images.cuda()\n",
    "    images = extractor.forward(Variable(images))\n",
    "\n",
    "    temp = images.shape[0]\n",
    "    images = torch.stack([images] * captions_per_image).permute(1, 0, 2).contiguous().view(-1, images.shape[-1])\n",
    "\n",
    "\n",
    "    # generator\n",
    "    rewards, props = generator.reward_forward(images, evaluator, monte_carlo_count=monte_carlo_count,steps=1)\n",
    "\n",
    "    generator_optimizer.zero_grad()\n",
    "    loss = generator_criterion(rewards, props)\n",
    "    batch_loss = loss.item()\n",
    "    generator_loss += batch_loss\n",
    "    \n",
    "    loss.backward()\n",
    "    generator_optimizer.step()\n",
    "    \n",
    "    print(f\"Batch = {i}, Time: {time.time() - batch_time}, Loss: {generator_loss}, Batch Loss: {batch_loss}\")\n",
    "    batch_time = time.time()\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "g_losses.append(generator_loss)\n",
    "print(f\"Epoch: {epoch}, Time: {end - start}, Loss: {generator_loss}\")\n",
    "\n",
    "# file_name = f\"generator-{epoch}.pth\"\n",
    "# torch.save({\"state_dict\": generator.state_dict(), 'epoch':epoch, 'losses': g_losses},\n",
    "#            FilePathManager.resolve(f\"models/{file_name}\"))\n",
    "# torch.save({\"state_dict\": generator.state_dict(), 'optimizer': generator_optimizer.state_dict(),'epoch':epoch, 'losses': g_losses},\n",
    "#            FilePathManager.resolve(f\"models/{file_name}\"))\n",
    "# upload_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "js-1l8_c2N7I"
   },
   "outputs": [],
   "source": [
    "# g_losses.append(generator_loss)\n",
    "print(f\"Epoch: {epoch}, Time: {end - start}, Loss: {generator_loss}\")\n",
    "\n",
    "file_name = f\"generator-{epoch}.pth\"\n",
    "torch.save({\"state_dict\": generator.state_dict(),'epoch':epoch, 'losses': g_losses},\n",
    "           FilePathManager.resolve(f\"models/{file_name}\"))\n",
    "upload_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ck-HLq9lUp1c"
   },
   "outputs": [],
   "source": [
    "e_losses = []\n",
    "max_length = 17\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VUw-GM0Q-rOu"
   },
   "outputs": [],
   "source": [
    "evaluator.unfreeze()\n",
    "generator.freeze()\n",
    "\n",
    "print(\"Begin Training Evaluator\")\n",
    "\n",
    "start = time.time()\n",
    "batch_loss = 0\n",
    "batch_time = time.time()\n",
    "evaluator_loss = 0\n",
    "for i, (images, captions, other_captions) in enumerate(e_dataloader):\n",
    "#     captions, other_captions = captions_loader.get_captions(indices)\n",
    "    images, captions, other_captions = images.cuda(), captions.cuda(), other_captions.cuda()\n",
    "\n",
    "    images = extractor.forward(Variable(images))\n",
    "    captions = captions.view(-1, max_length, captions.shape[-1])\n",
    "    other_captions = other_captions.view(-1, max_length, other_captions.shape[-1])\n",
    "\n",
    "    temp = images.shape[0]\n",
    "    images = torch.stack([images] * captions_per_image).permute(1, 0, 2).contiguous().view(-1, images.shape[-1])\n",
    "\n",
    "    # evaluator\n",
    "    captions = pack_padded_sequence(captions, [max_length] * temp * captions_per_image, True)\n",
    "    other_captions = pack_padded_sequence(other_captions, [max_length] * temp * captions_per_image, True)\n",
    "    generator_outputs = generator.sample_with_embedding(images)\n",
    "    evaluator_outputs = evaluator(images, captions)\n",
    "    generator_outputs = evaluator(images, generator_outputs)\n",
    "    other_outputs = evaluator(images, other_captions)\n",
    "    evaluator_criterion.zero_grad()\n",
    "    loss = evaluator_criterion(evaluator_outputs, generator_outputs, other_outputs)\n",
    "    batch_loss = loss.item()\n",
    "    evaluator_loss += batch_loss\n",
    "    loss.backward()\n",
    "    evaluator_optimizer.step()\n",
    "    \n",
    "\n",
    "    print(f\"Batch = {i}, Time: {time.time() - batch_time}, Loss: {evaluator_loss}, Batch Loss: {batch_loss}\")\n",
    "    batch_time = time.time()\n",
    "\n",
    "end = time.time()\n",
    "e_losses.append(evaluator_loss)\n",
    "print(f\"Epoch: {epoch}, Time: {end - start}, Loss: {evaluator_loss}\")\n",
    "start = end\n",
    "\n",
    "file_name = f\"evaluator-{epoch}.pth\"\n",
    "torch.save({\"state_dict\": evaluator.state_dict(), 'optimizer': evaluator_optimizer.state_dict(), 'epoch':epoch, 'losses': e_losses},\n",
    "           FilePathManager.resolve(f\"models/{file_name}\"))\n",
    "upload_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "CfxcPC8RiN-U"
   },
   "outputs": [],
   "source": [
    "e_losses = []\n",
    "e_losses.append(evaluator_loss)\n",
    "\n",
    "file_name = f\"evaluator-{epoch}.pth\"\n",
    "torch.save({\"state_dict\": evaluator.state_dict(), 'optimizer': evaluator_optimizer.state_dict(), 'e':e_losses, 'epoch':epoch, 'losses': all_losses},\n",
    "         FilePathManager.resolve(f\"models/{file_name}\"))\n",
    "upload_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7qPFl4ehiKrW"
   },
   "outputs": [],
   "source": [
    "\n",
    "file_name = f\"generator-{epoch}.pth\"\n",
    "torch.save({\"state_dict\": generator.state_dict(), 'epoch':epoch,'g':g_losses, 'losses': all_losses},\n",
    "         FilePathManager.resolve(f\"models/{file_name}\"))\n",
    "upload_file(file_name)\n",
    "\n",
    "file_name = f\"evaluator-{epoch}.pth\"\n",
    "torch.save({\"state_dict\": evaluator.state_dict(), 'epoch':epoch, 'e':e_losses, 'losses': all_losses},\n",
    "         FilePathManager.resolve(f\"models/{file_name}\"))\n",
    "upload_file(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YeNNa8NcB8uU"
   },
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TKMMjpMdC71O"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pretrainedmodels import utils\n",
    "\n",
    "from file_path_manager import FilePathManager\n",
    "\n",
    "load_img = utils.LoadImage()\n",
    "\n",
    "\n",
    "extractor2 = Vgg16Extractor(transform=True)\n",
    "extractor2.cnn = copy.deepcopy(vgg)\n",
    "extractor2.cnn.eval()\n",
    "extractor2.cnn.cuda()\n",
    "\n",
    "image_folder = FilePathManager.resolve(\"test_images/\")\n",
    "image1 = image_folder + \"image_1.png\"\n",
    "image2 = image_folder + \"image_2.jpg\"\n",
    "image3 = image_folder + \"image_3.jpg\"\n",
    "image4 = image_folder + \"image_4.jpg\"\n",
    "image5 = image_folder + \"image_5.jpg\"\n",
    "image6 = image_folder + \"image_6.jpg\"\n",
    "images = [image1, image2, image3, image4, image5, image6]\n",
    "\n",
    "print(\"Greedy Sample:\")\n",
    "for i, image in enumerate(images):\n",
    "    print(f\"{i+1}th Image:\")\n",
    "    image = load_img(image)\n",
    "    features = extractor2.forward(image)\n",
    "    for _ in range(5):\n",
    "        result = generator.sample(features)\n",
    "        print(result)\n",
    "\n",
    "print(\"Beam Search Sample:\")\n",
    "for i, image in enumerate(images):\n",
    "    print(f\"{i+1}th Image:\")\n",
    "    image = load_img(image)\n",
    "    features = extractor2.forward(image)\n",
    "    for _ in range(5):\n",
    "        result = generator.beam_sample(features, 10)\n",
    "        print(result)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "gan-caption.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
